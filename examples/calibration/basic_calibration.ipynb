{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "The objective of this example is to run the basic calibration steps on raw frames.\n",
    "By the end of this example, we will know how to:\n",
    "\n",
    "- Pre-process raw frames to remove the overscan section and extract the science section\n",
    "- Remove cosmic rays from individual frames using the L.A. algorithm (Van Dokkum+2005)\n",
    "- Produce calibrated bias, dark and pixelflat frames\n",
    "\n",
    "Let's start with some imports and function definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from lvmdrp.core.constants import LVM_SIM_URL\n",
    "from lvmdrp.utils.examples import GAINS, RDNOISES\n",
    "from lvmdrp.utils.examples import fetch_example_data, get_frames_metadata\n",
    "\n",
    "from lvmdrp.functions import imageMethod"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading 2D simulations\n",
    "\n",
    "Before we begin, we need to:\n",
    "- Define paths to input and output data\n",
    "- Download some data to run through the pipeline\n",
    "\n",
    "In this case, we'll download 2D simulated data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;34m[INFO]: \u001b[0mexample data already exists\n"
     ]
    }
   ],
   "source": [
    "# define input data directory\n",
    "data_path = os.path.abspath(os.path.join(\"..\", \"data\", \"data_simulator\", \"2d\"))\n",
    "\n",
    "# let's create the output directory\n",
    "output_path = os.path.join(\"data\")\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "# now we download the example data\n",
    "fetch_example_data(url=LVM_SIM_URL, compressed_name=\"lvmdrp_example_data.zip\", dest_path=os.path.abspath(\"..\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to organize our simulated data and target specific type of frames better,\n",
    "we extract relevant metadata from the frames and group them by image type, camera\n",
    "and exposure time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;34m[INFO]: \u001b[0mextracting metadata from 252 frames\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|######################################################################################################| 252/252 [00:59<00:00,  4.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;34m[INFO]: \u001b[0msuccessfully extracted metadata\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# extract metadata\n",
    "frames_table = get_frames_metadata(path=data_path)\n",
    "# group by imagetyp, camera and exptime\n",
    "frames_table = frames_table.group_by([\"imagetyp\", \"camera\", \"exptime\"])\n",
    "# define groups and unique categories in those groups\n",
    "frames_groups = frames_table.groups\n",
    "unique_groups = frames_groups.keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start by processing calibration frames: bias, dark and pixelflats\n",
    "\n",
    "Let's start with the biases for the blue channel of spectrograph #1..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gains_b = \",\".join(map(str, GAINS[\"b\"]))\n",
    "rdnoises_b = \",\".join(map(str, RDNOISES[\"b\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><i>Table length=8</i>\n",
       "<table id=\"table140510527254640\" class=\"table-striped table-bordered table-condensed\">\n",
       "<thead><tr><th>imagetyp</th><th>spec</th><th>camera</th><th>expnum</th><th>exptime</th><th>path</th></tr></thead>\n",
       "<thead><tr><th>str9</th><th>str3</th><th>str2</th><th>str8</th><th>float64</th><th>str105</th></tr></thead>\n",
       "<tr><td>bias</td><td>sp1</td><td>b1</td><td>00000018</td><td>900.14</td><td>/home/mejia/Research/UNAM/lvm-drp/lvmdrp/examples/data/data_simulator/2d/bias/sdR-b1-00000018.fit.gz</td></tr>\n",
       "<tr><td>bias</td><td>sp1</td><td>b1</td><td>00000017</td><td>900.14</td><td>/home/mejia/Research/UNAM/lvm-drp/lvmdrp/examples/data/data_simulator/2d/bias/sdR-b1-00000017.fit.gz</td></tr>\n",
       "<tr><td>bias</td><td>sp1</td><td>b1</td><td>00000001</td><td>900.14</td><td>/home/mejia/Research/UNAM/lvm-drp/lvmdrp/examples/data/data_simulator/2d/bias/sdR-b1-00000001.fit.gz</td></tr>\n",
       "<tr><td>bias</td><td>sp1</td><td>b1</td><td>00000002</td><td>900.14</td><td>/home/mejia/Research/UNAM/lvm-drp/lvmdrp/examples/data/data_simulator/2d/bias/sdR-b1-00000002.fit.gz</td></tr>\n",
       "<tr><td>bias</td><td>sp1</td><td>b1</td><td>00000000</td><td>900.14</td><td>/home/mejia/Research/UNAM/lvm-drp/lvmdrp/examples/data/data_simulator/2d/bias/sdR-b1-00000000.fit.gz</td></tr>\n",
       "<tr><td>bias</td><td>sp1</td><td>b1</td><td>00000003</td><td>900.14</td><td>/home/mejia/Research/UNAM/lvm-drp/lvmdrp/examples/data/data_simulator/2d/bias/sdR-b1-00000003.fit.gz</td></tr>\n",
       "<tr><td>bias</td><td>sp1</td><td>b1</td><td>00000019</td><td>900.14</td><td>/home/mejia/Research/UNAM/lvm-drp/lvmdrp/examples/data/data_simulator/2d/bias/sdR-b1-00000019.fit.gz</td></tr>\n",
       "<tr><td>bias</td><td>sp1</td><td>b1</td><td>00000004</td><td>900.14</td><td>/home/mejia/Research/UNAM/lvm-drp/lvmdrp/examples/data/data_simulator/2d/bias/sdR-b1-00000004.fit.gz</td></tr>\n",
       "</table></div>"
      ],
      "text/plain": [
       "<Table length=8>\n",
       "imagetyp spec camera  expnum  exptime                                                 path                                                \n",
       "  str9   str3  str2    str8   float64                                                str105                                               \n",
       "-------- ---- ------ -------- ------- ----------------------------------------------------------------------------------------------------\n",
       "    bias  sp1     b1 00000018  900.14 /home/mejia/Research/UNAM/lvm-drp/lvmdrp/examples/data/data_simulator/2d/bias/sdR-b1-00000018.fit.gz\n",
       "    bias  sp1     b1 00000017  900.14 /home/mejia/Research/UNAM/lvm-drp/lvmdrp/examples/data/data_simulator/2d/bias/sdR-b1-00000017.fit.gz\n",
       "    bias  sp1     b1 00000001  900.14 /home/mejia/Research/UNAM/lvm-drp/lvmdrp/examples/data/data_simulator/2d/bias/sdR-b1-00000001.fit.gz\n",
       "    bias  sp1     b1 00000002  900.14 /home/mejia/Research/UNAM/lvm-drp/lvmdrp/examples/data/data_simulator/2d/bias/sdR-b1-00000002.fit.gz\n",
       "    bias  sp1     b1 00000000  900.14 /home/mejia/Research/UNAM/lvm-drp/lvmdrp/examples/data/data_simulator/2d/bias/sdR-b1-00000000.fit.gz\n",
       "    bias  sp1     b1 00000003  900.14 /home/mejia/Research/UNAM/lvm-drp/lvmdrp/examples/data/data_simulator/2d/bias/sdR-b1-00000003.fit.gz\n",
       "    bias  sp1     b1 00000019  900.14 /home/mejia/Research/UNAM/lvm-drp/lvmdrp/examples/data/data_simulator/2d/bias/sdR-b1-00000019.fit.gz\n",
       "    bias  sp1     b1 00000004  900.14 /home/mejia/Research/UNAM/lvm-drp/lvmdrp/examples/data/data_simulator/2d/bias/sdR-b1-00000004.fit.gz"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# OK, biases have exptime != 0 for some reason...\n",
    "biases = frames_groups[(unique_groups[\"imagetyp\"]==\"bias\")&(unique_groups[\"camera\"]==\"b1\")]\n",
    "biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# let's pre-process the first bias frame\n",
    "bias_frame = biases[0]\n",
    "bias_path = bias_frame[\"path\"]\n",
    "bias_camera, bias_expnum = bias_frame[\"camera\"], bias_frame[\"expnum\"]\n",
    "imageMethod.preprocRawFrame_drp(\n",
    "    in_image=bias_path,\n",
    "    out_image=os.path.join(output_path, f\"lvm-pbias-{bias_camera}-{bias_expnum}.fits\"),\n",
    "    subtract_overscan=False, unit=\"e-\", compute_error=True,\n",
    "    assume_imagetyp=\"bias\", assume_gain=gains_b, assume_rdnoise=rdnoises_b\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><i>Table length=10</i>\n",
       "<table id=\"table140510527258240\" class=\"table-striped table-bordered table-condensed\">\n",
       "<thead><tr><th>imagetyp</th><th>spec</th><th>camera</th><th>expnum</th><th>exptime</th><th>path</th></tr></thead>\n",
       "<thead><tr><th>str9</th><th>str3</th><th>str2</th><th>str8</th><th>float64</th><th>str105</th></tr></thead>\n",
       "<tr><td>dark</td><td>sp1</td><td>b1</td><td>00000024</td><td>10.14</td><td>/home/mejia/Research/UNAM/lvm-drp/lvmdrp/examples/data/data_simulator/2d/dark/sdR-b1-00000024.fit.gz</td></tr>\n",
       "<tr><td>dark</td><td>sp1</td><td>b1</td><td>00000025</td><td>100.14</td><td>/home/mejia/Research/UNAM/lvm-drp/lvmdrp/examples/data/data_simulator/2d/dark/sdR-b1-00000025.fit.gz</td></tr>\n",
       "<tr><td>dark</td><td>sp1</td><td>b1</td><td>00000026</td><td>200.14</td><td>/home/mejia/Research/UNAM/lvm-drp/lvmdrp/examples/data/data_simulator/2d/dark/sdR-b1-00000026.fit.gz</td></tr>\n",
       "<tr><td>dark</td><td>sp1</td><td>b1</td><td>00000027</td><td>300.14</td><td>/home/mejia/Research/UNAM/lvm-drp/lvmdrp/examples/data/data_simulator/2d/dark/sdR-b1-00000027.fit.gz</td></tr>\n",
       "<tr><td>dark</td><td>sp1</td><td>b1</td><td>00000028</td><td>400.14</td><td>/home/mejia/Research/UNAM/lvm-drp/lvmdrp/examples/data/data_simulator/2d/dark/sdR-b1-00000028.fit.gz</td></tr>\n",
       "<tr><td>dark</td><td>sp1</td><td>b1</td><td>00000029</td><td>500.14</td><td>/home/mejia/Research/UNAM/lvm-drp/lvmdrp/examples/data/data_simulator/2d/dark/sdR-b1-00000029.fit.gz</td></tr>\n",
       "<tr><td>dark</td><td>sp1</td><td>b1</td><td>00000030</td><td>750.14</td><td>/home/mejia/Research/UNAM/lvm-drp/lvmdrp/examples/data/data_simulator/2d/dark/sdR-b1-00000030.fit.gz</td></tr>\n",
       "<tr><td>dark</td><td>sp1</td><td>b1</td><td>00000031</td><td>1000.14</td><td>/home/mejia/Research/UNAM/lvm-drp/lvmdrp/examples/data/data_simulator/2d/dark/sdR-b1-00000031.fit.gz</td></tr>\n",
       "<tr><td>dark</td><td>sp1</td><td>b1</td><td>00000032</td><td>1500.14</td><td>/home/mejia/Research/UNAM/lvm-drp/lvmdrp/examples/data/data_simulator/2d/dark/sdR-b1-00000032.fit.gz</td></tr>\n",
       "<tr><td>dark</td><td>sp1</td><td>b1</td><td>00000033</td><td>2000.14</td><td>/home/mejia/Research/UNAM/lvm-drp/lvmdrp/examples/data/data_simulator/2d/dark/sdR-b1-00000033.fit.gz</td></tr>\n",
       "</table></div>"
      ],
      "text/plain": [
       "<Table length=10>\n",
       "imagetyp spec camera  expnum  exptime                                                 path                                                \n",
       "  str9   str3  str2    str8   float64                                                str105                                               \n",
       "-------- ---- ------ -------- ------- ----------------------------------------------------------------------------------------------------\n",
       "    dark  sp1     b1 00000024   10.14 /home/mejia/Research/UNAM/lvm-drp/lvmdrp/examples/data/data_simulator/2d/dark/sdR-b1-00000024.fit.gz\n",
       "    dark  sp1     b1 00000025  100.14 /home/mejia/Research/UNAM/lvm-drp/lvmdrp/examples/data/data_simulator/2d/dark/sdR-b1-00000025.fit.gz\n",
       "    dark  sp1     b1 00000026  200.14 /home/mejia/Research/UNAM/lvm-drp/lvmdrp/examples/data/data_simulator/2d/dark/sdR-b1-00000026.fit.gz\n",
       "    dark  sp1     b1 00000027  300.14 /home/mejia/Research/UNAM/lvm-drp/lvmdrp/examples/data/data_simulator/2d/dark/sdR-b1-00000027.fit.gz\n",
       "    dark  sp1     b1 00000028  400.14 /home/mejia/Research/UNAM/lvm-drp/lvmdrp/examples/data/data_simulator/2d/dark/sdR-b1-00000028.fit.gz\n",
       "    dark  sp1     b1 00000029  500.14 /home/mejia/Research/UNAM/lvm-drp/lvmdrp/examples/data/data_simulator/2d/dark/sdR-b1-00000029.fit.gz\n",
       "    dark  sp1     b1 00000030  750.14 /home/mejia/Research/UNAM/lvm-drp/lvmdrp/examples/data/data_simulator/2d/dark/sdR-b1-00000030.fit.gz\n",
       "    dark  sp1     b1 00000031 1000.14 /home/mejia/Research/UNAM/lvm-drp/lvmdrp/examples/data/data_simulator/2d/dark/sdR-b1-00000031.fit.gz\n",
       "    dark  sp1     b1 00000032 1500.14 /home/mejia/Research/UNAM/lvm-drp/lvmdrp/examples/data/data_simulator/2d/dark/sdR-b1-00000032.fit.gz\n",
       "    dark  sp1     b1 00000033 2000.14 /home/mejia/Research/UNAM/lvm-drp/lvmdrp/examples/data/data_simulator/2d/dark/sdR-b1-00000033.fit.gz"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "darks = frames_groups[(unique_groups[\"imagetyp\"]==\"dark\")&(unique_groups[\"camera\"]==\"b1\")]\n",
    "darks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# now let's pre-process one dark\n",
    "dark_frame = darks[1]\n",
    "dark_path = dark_frame[\"path\"]\n",
    "dark_camera, dark_expnum = dark_frame[\"camera\"], dark_frame[\"expnum\"]\n",
    "imageMethod.preprocRawFrame_drp(\n",
    "    in_image=dark_path,\n",
    "    out_image=os.path.join(output_path, f\"lvm-pdark-{dark_camera}-{dark_expnum}.fits\"),\n",
    "    subtract_overscan=False, unit=\"e-\", compute_error=True,\n",
    "    assume_imagetyp=\"dark\", assume_gain=gains_b, assume_rdnoise=rdnoises_b\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pixelflats = frames_groups[(unique_groups[\"imagetyp\"]==\"dark\")&(unique_groups[\"camera\"]==\"b1\")]\n",
    "pixelflats\n",
    "\n",
    "pixelflat_frame = pixelflats[4]\n",
    "pixelflat_path = pixelflat_frame[\"path\"]\n",
    "pixelflat_camera, pixelflat_expnum = pixelflat_frame[\"camera\"], pixelflat_frame[\"expnum\"]\n",
    "imageMethod.preprocRawFrame_drp(\n",
    "    in_image=pixelflat_path,\n",
    "    out_image=os.path.join(output_path, f\"lvm-ppixelflat-{pixelflat_camera}-{pixelflat_expnum}.fits\"),\n",
    "    subtract_overscan=False, unit=\"e-\", compute_error=True,\n",
    "    assume_imagetyp=\"flatfield\", assume_gain=gains_b, assume_rdnoise=rdnoises_b\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# because we will be using individual exposures to calibrate, let's reject those cosmic rays\n",
    "imageMethod.LACosmic_drp(\n",
    "    in_image=os.path.join(output_path, f\"lvm-pbias-{bias_camera}-{bias_expnum}.fits\"),\n",
    "    out_image=os.path.join(output_path, f\"lvm-rbias-{bias_camera}-{bias_expnum}.fits\"),\n",
    "    iter=3, increase_radius=1, flim=1.3, parallel=\"auto\"\n",
    ")\n",
    "imageMethod.LACosmic_drp(\n",
    "    in_image=os.path.join(output_path, f\"lvm-pdark-{dark_camera}-{dark_expnum}.fits\"),\n",
    "    out_image=os.path.join(output_path, f\"lvm-rdark-{dark_camera}-{dark_expnum}.fits\"),\n",
    "    iter=3, increase_radius=1, flim=1.3, parallel=\"auto\"\n",
    ")\n",
    "imageMethod.LACosmic_drp(\n",
    "    in_image=os.path.join(output_path, f\"lvm-ppixelflat-{pixelflat_camera}-{pixelflat_expnum}.fits\"),\n",
    "    out_image=os.path.join(output_path, f\"lvm-rpixelflat-{pixelflat_camera}-{pixelflat_expnum}.fits\"),\n",
    "    iter=3, increase_radius=1, flim=1.3, parallel=\"auto\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# the next step will be to reduce each calibration frame\n",
    "# in general this implies:\n",
    "#   * subtracting the bias\n",
    "#   * subtracting the dark\n",
    "#   * and flat fielding\n",
    "\n",
    "# start with the dark frame\n",
    "imageMethod.basicCalibration_drp(\n",
    "    in_image=os.path.join(output_path, f\"lvm-rdark-{dark_camera}-{dark_expnum}.fits\"),\n",
    "    out_image=os.path.join(output_path, f\"lvm-cdark-{dark_camera}-{dark_expnum}.fits\"),\n",
    "    in_bias=os.path.join(output_path, f\"lvm-rbias-{bias_camera}-{bias_expnum}.fits\")\n",
    ")\n",
    "# and continue with the pixelflat\n",
    "imageMethod.basicCalibration_drp(\n",
    "    in_image=os.path.join(output_path, f\"lvm-rpixelflat-{pixelflat_camera}-{pixelflat_expnum}.fits\"),\n",
    "    out_image=os.path.join(output_path, f\"lvm-cpixelflat-{pixelflat_camera}-{pixelflat_expnum}.fits\"),\n",
    "    in_bias=os.path.join(output_path, f\"lvm-rbias-{bias_camera}-{bias_expnum}.fits\"),\n",
    "    in_dark=os.path.join(output_path, f\"lvm-cdark-{dark_camera}-{dark_expnum}.fits\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><i>Table length=4</i>\n",
       "<table id=\"table140510527534992\" class=\"table-striped table-bordered table-condensed\">\n",
       "<thead><tr><th>imagetyp</th><th>spec</th><th>camera</th><th>expnum</th><th>exptime</th><th>path</th></tr></thead>\n",
       "<thead><tr><th>str9</th><th>str3</th><th>str2</th><th>str8</th><th>float64</th><th>str105</th></tr></thead>\n",
       "<tr><td>fiberflat</td><td>sp1</td><td>b1</td><td>00000022</td><td>25.14</td><td>/home/mejia/Research/UNAM/lvm-drp/lvmdrp/examples/data/data_simulator/2d/fiberflat/sdR-b1-00000022.fit.gz</td></tr>\n",
       "<tr><td>fiberflat</td><td>sp1</td><td>b1</td><td>00000005</td><td>25.14</td><td>/home/mejia/Research/UNAM/lvm-drp/lvmdrp/examples/data/data_simulator/2d/fiberflat/sdR-b1-00000005.fit.gz</td></tr>\n",
       "<tr><td>fiberflat</td><td>sp1</td><td>b1</td><td>00000023</td><td>25.14</td><td>/home/mejia/Research/UNAM/lvm-drp/lvmdrp/examples/data/data_simulator/2d/fiberflat/sdR-b1-00000023.fit.gz</td></tr>\n",
       "<tr><td>fiberflat</td><td>sp1</td><td>b1</td><td>00000006</td><td>25.14</td><td>/home/mejia/Research/UNAM/lvm-drp/lvmdrp/examples/data/data_simulator/2d/fiberflat/sdR-b1-00000006.fit.gz</td></tr>\n",
       "</table></div>"
      ],
      "text/plain": [
       "<Table length=4>\n",
       " imagetyp spec camera ... exptime                                                    path                                                  \n",
       "   str9   str3  str2  ... float64                                                   str105                                                 \n",
       "--------- ---- ------ ... ------- ---------------------------------------------------------------------------------------------------------\n",
       "fiberflat  sp1     b1 ...   25.14 /home/mejia/Research/UNAM/lvm-drp/lvmdrp/examples/data/data_simulator/2d/fiberflat/sdR-b1-00000022.fit.gz\n",
       "fiberflat  sp1     b1 ...   25.14 /home/mejia/Research/UNAM/lvm-drp/lvmdrp/examples/data/data_simulator/2d/fiberflat/sdR-b1-00000005.fit.gz\n",
       "fiberflat  sp1     b1 ...   25.14 /home/mejia/Research/UNAM/lvm-drp/lvmdrp/examples/data/data_simulator/2d/fiberflat/sdR-b1-00000023.fit.gz\n",
       "fiberflat  sp1     b1 ...   25.14 /home/mejia/Research/UNAM/lvm-drp/lvmdrp/examples/data/data_simulator/2d/fiberflat/sdR-b1-00000006.fit.gz"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fiberflats = frames_groups[(unique_groups[\"imagetyp\"]==\"fiberflat\")&(unique_groups[\"camera\"]==\"b1\")]\n",
    "fiberflats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Now that we have calibration frames, let's calibrate a fiberflat and an arc\n",
    "\n",
    "fiberflat_frame = fiberflats[0]\n",
    "fiberflat_path = fiberflat_frame[\"path\"]\n",
    "fiberflat_camera, fiberflat_expnum = fiberflat_frame[\"camera\"], fiberflat_frame[\"expnum\"]\n",
    "imageMethod.preprocRawFrame_drp(\n",
    "    in_image=fiberflat_path,\n",
    "    out_image=os.path.join(output_path, f\"lvm-pfiberflat-{fiberflat_camera}-{fiberflat_expnum}.fits\"),\n",
    "    subtract_overscan=False, unit=\"e-\", compute_error=True,\n",
    "    assume_imagetyp=\"fiberflat\", assume_gain=gains_b, assume_rdnoise=rdnoises_b\n",
    ")\n",
    "imageMethod.LACosmic_drp(\n",
    "    in_image=os.path.join(output_path, f\"lvm-pfiberflat-{fiberflat_camera}-{fiberflat_expnum}.fits\"),\n",
    "    out_image=os.path.join(output_path, f\"lvm-rfiberflat-{fiberflat_camera}-{fiberflat_expnum}.fits\"),\n",
    "    iter=3, increase_radius=1, flim=1.3, parallel=\"auto\"\n",
    ")\n",
    "imageMethod.basicCalibration_drp(\n",
    "    in_image=os.path.join(output_path, f\"lvm-rfiberflat-{fiberflat_camera}-{fiberflat_expnum}.fits\"),\n",
    "    out_image=os.path.join(output_path, f\"lvm-cfiberflat-{fiberflat_camera}-{fiberflat_expnum}.fits\"),\n",
    "    in_bias=os.path.join(output_path, f\"lvm-rbias-{bias_camera}-{bias_expnum}.fits\"),\n",
    "    in_dark=os.path.join(output_path, f\"lvm-cdark-{dark_camera}-{dark_expnum}.fits\"),\n",
    "    in_pixelflat=os.path.join(output_path, f\"lvm-cpixelflat-{pixelflat_camera}-{pixelflat_expnum}.fits\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><i>Table length=4</i>\n",
       "<table id=\"table140510527934224\" class=\"table-striped table-bordered table-condensed\">\n",
       "<thead><tr><th>imagetyp</th><th>spec</th><th>camera</th><th>expnum</th><th>exptime</th><th>path</th></tr></thead>\n",
       "<thead><tr><th>str9</th><th>str3</th><th>str2</th><th>str8</th><th>float64</th><th>str105</th></tr></thead>\n",
       "<tr><td>arc</td><td>sp1</td><td>b1</td><td>00000021</td><td>4.14</td><td>/home/mejia/Research/UNAM/lvm-drp/lvmdrp/examples/data/data_simulator/2d/arc/sdR-b1-00000021.fit.gz</td></tr>\n",
       "<tr><td>arc</td><td>sp1</td><td>b1</td><td>00000007</td><td>4.14</td><td>/home/mejia/Research/UNAM/lvm-drp/lvmdrp/examples/data/data_simulator/2d/arc/sdR-b1-00000007.fit.gz</td></tr>\n",
       "<tr><td>arc</td><td>sp1</td><td>b1</td><td>00000020</td><td>4.14</td><td>/home/mejia/Research/UNAM/lvm-drp/lvmdrp/examples/data/data_simulator/2d/arc/sdR-b1-00000020.fit.gz</td></tr>\n",
       "<tr><td>arc</td><td>sp1</td><td>b1</td><td>00000008</td><td>4.14</td><td>/home/mejia/Research/UNAM/lvm-drp/lvmdrp/examples/data/data_simulator/2d/arc/sdR-b1-00000008.fit.gz</td></tr>\n",
       "</table></div>"
      ],
      "text/plain": [
       "<Table length=4>\n",
       "imagetyp spec camera  expnum  exptime                                                 path                                               \n",
       "  str9   str3  str2    str8   float64                                                str105                                              \n",
       "-------- ---- ------ -------- ------- ---------------------------------------------------------------------------------------------------\n",
       "     arc  sp1     b1 00000021    4.14 /home/mejia/Research/UNAM/lvm-drp/lvmdrp/examples/data/data_simulator/2d/arc/sdR-b1-00000021.fit.gz\n",
       "     arc  sp1     b1 00000007    4.14 /home/mejia/Research/UNAM/lvm-drp/lvmdrp/examples/data/data_simulator/2d/arc/sdR-b1-00000007.fit.gz\n",
       "     arc  sp1     b1 00000020    4.14 /home/mejia/Research/UNAM/lvm-drp/lvmdrp/examples/data/data_simulator/2d/arc/sdR-b1-00000020.fit.gz\n",
       "     arc  sp1     b1 00000008    4.14 /home/mejia/Research/UNAM/lvm-drp/lvmdrp/examples/data/data_simulator/2d/arc/sdR-b1-00000008.fit.gz"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arcs = frames_groups[(unique_groups[\"imagetyp\"]==\"arc\")&(unique_groups[\"camera\"]==\"b1\")]\n",
    "arcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "arc_frame = arcs[0]\n",
    "arc_path = arc_frame[\"path\"]\n",
    "arc_camera, arc_expnum = arc_frame[\"camera\"], arc_frame[\"expnum\"]\n",
    "imageMethod.preprocRawFrame_drp(\n",
    "    in_image=arc_path,\n",
    "    out_image=os.path.join(output_path, f\"lvm-parc-{arc_camera}-{arc_expnum}.fits\"),\n",
    "    subtract_overscan=False, unit=\"e-\", compute_error=True,\n",
    "    assume_imagetyp=\"arc\", assume_gain=gains_b, assume_rdnoise=rdnoises_b\n",
    ")\n",
    "imageMethod.LACosmic_drp(\n",
    "    in_image=os.path.join(output_path, f\"lvm-parc-{arc_camera}-{arc_expnum}.fits\"),\n",
    "    out_image=os.path.join(output_path, f\"lvm-rarc-{arc_camera}-{arc_expnum}.fits\"),\n",
    "    iter=3, increase_radius=1, flim=1.3, parallel=\"auto\"\n",
    ")\n",
    "imageMethod.basicCalibration_drp(\n",
    "    in_image=os.path.join(output_path, f\"lvm-rarc-{arc_camera}-{arc_expnum}.fits\"),\n",
    "    out_image=os.path.join(output_path, f\"lvm-carc-{arc_camera}-{arc_expnum}.fits\"),\n",
    "    in_bias=os.path.join(output_path, f\"lvm-rbias-{bias_camera}-{bias_expnum}.fits\"),\n",
    "    in_dark=os.path.join(output_path, f\"lvm-cdark-{dark_camera}-{dark_expnum}.fits\"),\n",
    "    in_pixelflat=os.path.join(output_path, f\"lvm-cpixelflat-{pixelflat_camera}-{pixelflat_expnum}.fits\")\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "75b7dc73e2cd5987d39e44d45f1d2594b18b07dc05e2cece7d250df00c95241b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
